{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give your file paths \n",
    "pos = open(r'C:\\Users\\avishek\\Downloads\\DataFiles\\reviews\\positive.txt', 'r').read()\n",
    "neg = open(r'C:\\Users\\avishek\\Downloads\\DataFiles\\reviews\\negative.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "all_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in pos.split('\\n'):\n",
    "#     documents.append((r, 'pos'))\n",
    "\n",
    "# for r in neg.split('\\n'):\n",
    "#     documents.append((r, 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_pos = [\"J\"] #its for adjectives , you can use any POS's\n",
    "\n",
    "for p in pos.split('\\n'):\n",
    "    documents.append( (p, \"pos\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_pos:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "for p in neg.split('\\n'):\n",
    "    documents.append( (p, \"neg\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_pos:\n",
    "            all_words.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos_words = list(map(lambda x : x.lower(), word_tokenize(pos)))\n",
    "# neg_words = list(map(lambda x : x.lower(), word_tokenize(neg)))\n",
    "# pos_words = word_tokenize(pos)\n",
    "# neg_words = word_tokenize(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(pos_words),len(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neg_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words = pos_words + neg_words\n",
    "# for w in pos_words:\n",
    "#     all_words.append(w.lower())\n",
    "\n",
    "# for w in neg_words:\n",
    "#     all_words.append(w.lower())\n",
    "\n",
    "# allowed_pos = [\"J\"] #its for adjectives , you can use any POS's\n",
    "# for w in pos_words:\n",
    "#     p_o_s = nltk.pos_tag([w])\n",
    "#     if p_o_s[0][1][0] in allowed_pos:\n",
    "#         all_words.append(w.lower())\n",
    "\n",
    "# for w in neg_words:\n",
    "#     p_o_s = nltk.pos_tag([w])\n",
    "#     if p_o_s[0][1][0] in allowed_pos:\n",
    "#         all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26284"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 369),\n",
       " ('more', 331),\n",
       " ('little', 265),\n",
       " ('funny', 245),\n",
       " ('much', 234),\n",
       " ('bad', 234),\n",
       " ('best', 208),\n",
       " ('new', 206),\n",
       " ('own', 185),\n",
       " ('many', 183)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "all_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6188"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6188"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(all_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:5000] #train for top 5000 words, you can choose any no. the more the better and more slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21st',\n",
       " 'new',\n",
       " 'conan',\n",
       " 'greater',\n",
       " 'jean-claud',\n",
       " 'steven',\n",
       " 'elaborate',\n",
       " 'huge',\n",
       " 'expanded',\n",
       " 'effective']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_words.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    #words = list(map(lambda x : x.lower(), word_tokenize(document)))\n",
    "    w = word_tokenize(document)\n",
    "    words = set(w)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "        \n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10664"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(featuresets) # we can also do random.shuffle(documents) before declaring featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = featuresets[:10000]\n",
    "testing_set = featuresets[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('accuracy', 72.89156626506023)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'accuracy',nltk.classify.accuracy(classifier, testing_set)*100 \n",
    "# accuracies vary by running the code again and again as randon.shuffle changes the everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  boring = True              neg : pos    =     18.7 : 1.0\n",
      "                  stupid = True              neg : pos    =     17.8 : 1.0\n",
      "                 generic = True              neg : pos    =     16.5 : 1.0\n",
      "                 routine = True              neg : pos    =     15.1 : 1.0\n",
      "               inventive = True              pos : neg    =     14.9 : 1.0\n",
      "                mediocre = True              neg : pos    =     14.4 : 1.0\n",
      "              unexpected = True              pos : neg    =     14.2 : 1.0\n",
      "                    flat = True              neg : pos    =     13.9 : 1.0\n",
      "               wonderful = True              pos : neg    =     12.9 : 1.0\n",
      "              refreshing = True              pos : neg    =     12.9 : 1.0\n",
      "                    warm = True              pos : neg    =     12.5 : 1.0\n",
      "                   stale = True              neg : pos    =     11.8 : 1.0\n",
      "                mindless = True              neg : pos    =     11.8 : 1.0\n",
      "             mesmerizing = True              pos : neg    =     11.6 : 1.0\n",
      "               realistic = True              pos : neg    =     10.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "'most informative features'\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit Learn for above problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier # wrapper to include scikit learn classifier witin NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MN accuracy', 71.98795180722891)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MN_classifier = SklearnClassifier(MultinomialNB())\n",
    "MN_classifier.train(training_set)\n",
    "'MN accuracy',nltk.classify.accuracy(MN_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BR accuracy', 72.59036144578313)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BR_classifier = SklearnClassifier(BernoulliNB())\n",
    "BR_classifier.train(training_set)\n",
    "'BR accuracy',nltk.classify.accuracy(BR_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR accuracy', 68.67469879518072)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier = SklearnClassifier(LogisticRegression())\n",
    "LR_classifier.train(training_set)\n",
    "'LR accuracy',nltk.classify.accuracy(LR_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD_classifier = SklearnClassifier(SGDClassifier())\n",
    "# SGD_classifier.train(training_set)\n",
    "# 'SGD accuracy',nltk.classify.accuracy(SGD_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NSV accuracy', 68.52409638554217)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NSV_classifier = SklearnClassifier(NuSVC())\n",
    "NSV_classifier.train(training_set)\n",
    "'NSV accuracy',nltk.classify.accuracy(NSV_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Combining algos with a voting system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "        \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            votes.append(c.classify(features))\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            votes.append(c.classify(features))\n",
    "        \n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(classifier, MN_classifier, LR_classifier, BR_classifier, NSV_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('voted accuracy', 71.6867469879518)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'voted accuracy',nltk.classify.accuracy(voted_classifier, testing_set)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        In case the above 2 cells seem confusing (see the below link)\n",
    "        as we can see we have to define our own classify function and rest all the things will work as before .. \n",
    "        i still didnt get it completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [link](http://www.nltk.org/api/nltk.classify.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('classified for training set[50][0]', 'neg')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'classified for training set[50][0]',voted_classifier.classify(testing_set[11][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('confidence for training set[50][0]', 0.6)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'confidence for training set[50][0]',voted_classifier.confidence(testing_set[11][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 1.0)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with our own review:\n",
    "demo_review = \"the movie was awesome, the acting was great and amazing actions, overall a good bang for the bucks\"\n",
    "demo_review_featureset = find_features(demo_review)\n",
    "voted_classifier.classify(demo_review_featureset),voted_classifier.confidence(demo_review_featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 1.0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with our own review:\n",
    "demo_review = \"the movie was garbage, the acting was poor and garbage actions, waste of money\"\n",
    "demo_review_featureset = find_features(demo_review)\n",
    "voted_classifier.classify(demo_review_featureset),voted_classifier.confidence(demo_review_featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 1.0)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with our own review:\n",
    "demo_review = \"average movie, good actions but bad acting, storyline was decent but direction not so much\"\n",
    "demo_review_featureset = find_features(demo_review)\n",
    "voted_classifier.classify(demo_review_featureset),voted_classifier.confidence(demo_review_featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
